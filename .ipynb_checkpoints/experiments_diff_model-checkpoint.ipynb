{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7257b5-88d2-4dde-95ee-d3b1c9977347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_generation.generate_graph import generate_erdos_renyi_graph, generate_erdos_renyi_attribute_graph, generate_barabasi_albert_graph, generate_barabasi_albert_attribute_graph\n",
    "from diffusion_models.edge_probabilities import generate_edge_probabilities\n",
    "from diffusion_models.independent_cascade import optimized_independent_cascade, dmp_ic, ALE_heuristic, modified_ALE, ALE_heuristic_transpose, IC_approx_vectorized, IC_approx_vectorized_torch\n",
    "from influence_maximization.im import im_ic, im_diff\n",
    "from training.train_edge_gnn import train_diffusion_gnn, train_edge_model_with_diffusion, train_edge_model\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.data import Data\n",
    "from models.gnn_model import LearnableDiffusionGNN, MultiplicativeDiffusionGNN, ALE, ModifiedALE, ICApproxLayer, InfluenceSpreadNN, ICApproxLossModule\n",
    "from plotting_tools.prob_plots import posterior_plots, edge_plots\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from scipy import stats\n",
    "import time\n",
    "import random\n",
    "size_x=10\n",
    "size_y=3.5\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)                  \n",
    "np.random.seed(seed)              \n",
    "torch.manual_seed(seed)          \n",
    "torch.cuda.manual_seed(seed)     \n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d8732b-faca-471b-97cb-c68ba7c3436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_stats(rmse, pearson, spearman, auc, time_ic_apporx, time_mc):\n",
    "    ci_low, ci_high = stats.t.interval(0.95, df=len(rmse)-1, loc=rmse.mean(), scale=stats.sem(rmse))\n",
    "    print(f\"rmse:\\n mean={rmse.mean()},\\n ci_low={ci_low},\\n ci_high={ci_high},\\n std={rmse.std()}\")\n",
    "\n",
    "    ci_low, ci_high = stats.t.interval(0.95, df=len(pearson)-1, loc=pearson.mean(), scale=stats.sem(pearson))\n",
    "    print(f\"pearson:\\n mean={pearson.mean()},\\n ci_low={ci_low},\\n ci_high={ci_high},\\n std={pearson.std()}\")\n",
    "\n",
    "    ci_low, ci_high = stats.t.interval(0.95, df=len(spearman)-1, loc=spearman.mean(), scale=stats.sem(spearman))\n",
    "    print(f\"spearman:\\n mean={spearman.mean()},\\n ci_low={ci_low},\\n ci_high={ci_high},\\n std={spearman.std()}\")\n",
    "\n",
    "    ci_low, ci_high = stats.t.interval(0.95, df=len(auc)-1, loc=auc.mean(), scale=stats.sem(auc))\n",
    "    print(f\"auc:\\n mean={auc.mean()},\\n ci_low={ci_low},\\n ci_high={ci_high},\\n std={auc.std()}\")\n",
    "\n",
    "    ci_low, ci_high = stats.t.interval(0.95, df=len(time_ic_apporx)-1, loc=time_ic_apporx.mean(), scale=stats.sem(time_ic_apporx))\n",
    "    print(f\"time_ic_apporx:\\n mean={time_ic_apporx.mean()},\\n ci_low={ci_low},\\n ci_high={ci_high},\\n std={time_ic_apporx.std()}\")\n",
    "\n",
    "    ci_low, ci_high = stats.t.interval(0.95, df=len(time_mc)-1, loc=time_mc.mean(), scale=stats.sem(time_mc))\n",
    "    print(f\"time_mc:\\n mean={time_mc.mean()},\\n ci_low={ci_low},\\n ci_high={ci_high},\\n std={time_mc.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e930db62-1134-4c5b-b75a-270f73019ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal scalar: 0.9785, RMSE: 0.046203\n"
     ]
    }
   ],
   "source": [
    "def compute_rmse(scalar, G, edge_dict, prior_probs, T, true_posterior_tensor):\n",
    "    preds = IC_approx_vectorized(G, edge_dict, prior_probs, T, scalar)\n",
    "    preds_tensor = torch.tensor(preds, dtype=torch.float32).unsqueeze(1)\n",
    "    rmse = torch.nn.MSELoss()(preds_tensor, true_posterior_tensor).item() ** 0.5\n",
    "    return rmse\n",
    "\n",
    "def binary_search_optimal_scalar(G, edge_dict, prior_probs, T, true_posterior_tensor,\n",
    "                                  low=0, high=10, tolerance=1e-7, max_iter=30):\n",
    "    best_scalar = None\n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        mid1 = low + (high - low) / 3\n",
    "        mid2 = high - (high - low) / 3\n",
    "\n",
    "        rmse1 = compute_rmse(mid1, G, edge_dict, prior_probs, T, true_posterior_tensor)\n",
    "        rmse2 = compute_rmse(mid2, G, edge_dict, prior_probs, T, true_posterior_tensor)\n",
    "\n",
    "        if rmse1 < rmse2:\n",
    "            high = mid2\n",
    "            if rmse1 < best_rmse:\n",
    "                best_rmse = rmse1\n",
    "                best_scalar = mid1\n",
    "        else:\n",
    "            low = mid1\n",
    "            if rmse2 < best_rmse:\n",
    "                best_rmse = rmse2\n",
    "                best_scalar = mid2\n",
    "\n",
    "        if high - low < tolerance:\n",
    "            break\n",
    "\n",
    "    return best_scalar, best_rmse\n",
    "\n",
    "G, prior_probs = generate_barabasi_albert_graph(num_nodes = 1000,\n",
    "                                                    num_edges_per_node = 2,\n",
    "                                                    prob_selected = 0.1)\n",
    "    \n",
    "edge_dict = generate_edge_probabilities(G,method=\"degree_based\",low=0, high=1)\n",
    "\n",
    "ic = optimized_independent_cascade(G, prior_probs, edge_dict, 1000)\n",
    "\n",
    "true_posterior_tensor = torch.tensor(\n",
    "    [ic[node] for node in ic],\n",
    "    dtype=torch.float\n",
    ").view(-1, 1)\n",
    "\n",
    "optimal_scalar, min_rmse = binary_search_optimal_scalar(\n",
    "    G, edge_dict, prior_probs, 10, true_posterior_tensor\n",
    ")\n",
    "print(f\"Optimal scalar: {optimal_scalar:.4f}, RMSE: {min_rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cbc618-7f7d-4951-b42a-b3e796f96602",
   "metadata": {},
   "source": [
    "## Barabasi Albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "205ec2c0-1377-4a38-84fe-a7ee4a83be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes=1000\n",
    "num_edges_per_node=5 #2,5,10\n",
    "prob_selected = 0.1\n",
    "method=\"degree_based\"\n",
    "num_graphs=1\n",
    "num_sim=1000\n",
    "low=0\n",
    "high=1/3\n",
    "percentile=95\n",
    "T=10 # 5, 10, 15\n",
    "\n",
    "rmse = np.zeros(num_graphs)\n",
    "pearson = np.zeros(num_graphs)\n",
    "spearman = np.zeros(num_graphs)\n",
    "auc = np.zeros(num_graphs)\n",
    "time_ic_apporx = np.zeros(num_graphs)\n",
    "time_mc = np.zeros(num_graphs)\n",
    "\n",
    "for i in range(num_graphs):\n",
    "    G, prior_probs = generate_barabasi_albert_graph(num_nodes = num_nodes,\n",
    "                                                    num_edges_per_node = num_edges_per_node,\n",
    "                                                    prob_selected = prob_selected)\n",
    "    \n",
    "    edge_dict = generate_edge_probabilities(G,method=method,low=low, high=high)\n",
    "\n",
    "    start = time.time()\n",
    "    ic = optimized_independent_cascade(G, prior_probs, edge_dict, num_sim)\n",
    "    end = time.time()\n",
    "    time_mc[i] = end - start\n",
    "    true_posterior_tensor = torch.tensor(\n",
    "        [ic[node] for node in ic],\n",
    "        dtype=torch.float\n",
    "    ).view(-1, 1)\n",
    "\n",
    "    start = time.time()\n",
    "    preds = IC_approx_vectorized(G, edge_dict, prior_probs, T, 1)\n",
    "    end = time.time()\n",
    "    time_ic_apporx[i] = end - start\n",
    "    \n",
    "    preds_IC_approx = torch.tensor(preds, dtype=torch.float32).unsqueeze(1)\n",
    "    rmse[i] = torch.nn.MSELoss()(preds_IC_approx, true_posterior_tensor).item()**0.5\n",
    "\n",
    "    pearson[i] = torch.corrcoef(torch.stack([preds_IC_approx.squeeze(), true_posterior_tensor.squeeze()]))[0, 1]\n",
    "    spearman[i], _ = spearmanr(preds_IC_approx.squeeze(),\n",
    "                              true_posterior_tensor.squeeze())\n",
    "\n",
    "    y_true = true_posterior_tensor.squeeze().numpy()\n",
    "    y_score = preds_IC_approx.squeeze().numpy()\n",
    "    threshold = np.percentile(y_true, percentile)\n",
    "    y_binary = (y_true >= threshold).astype(int)\n",
    "    auc[i] = roc_auc_score(y_binary, y_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63252479-0b73-4682-b20d-e9735fda15d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:\n",
      " mean=0.017662977684403402,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "pearson:\n",
      " mean=0.9948218464851379,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "spearman:\n",
      " mean=0.9264459246869542,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "auc:\n",
      " mean=0.9998315789473684,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "time_ic_apporx:\n",
      " mean=0.006918430328369141,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "time_mc:\n",
      " mean=1.7893140316009521,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matic/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/matic/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "summarise_stats(rmse, pearson, spearman, auc, time_ic_apporx, time_mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7e3ea-f4c6-42bd-8a58-8dd34e406337",
   "metadata": {},
   "source": [
    "## Erdos Renyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e9a088b-b823-4233-8a7a-e5f7247e4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes=10000\n",
    "edge_prob=0.002 #0.0004, 0.0010, 0.0020\n",
    "prob_selected = 0.1\n",
    "method=\"degree_based\"\n",
    "num_graphs=10\n",
    "num_sim=10000\n",
    "low=0\n",
    "high=1/3\n",
    "percentile=95\n",
    "T=15 # 5, 10, 15\n",
    "\n",
    "rmse = np.zeros(num_graphs)\n",
    "pearson = np.zeros(num_graphs)\n",
    "spearman = np.zeros(num_graphs)\n",
    "auc = np.zeros(num_graphs)\n",
    "time_ic_apporx = np.zeros(num_graphs)\n",
    "time_mc = np.zeros(num_graphs)\n",
    "\n",
    "for i in range(num_graphs):\n",
    "    G, prior_probs = generate_erdos_renyi_graph(num_nodes = num_nodes,\n",
    "                                                    edge_prob = edge_prob,\n",
    "                                                    prob_selected = prob_selected,\n",
    "                                                    seed=seed)\n",
    "    \n",
    "    edge_dict = generate_edge_probabilities(G,method=method,low=low, high=high)\n",
    "\n",
    "    start = time.time()\n",
    "    ic = optimized_independent_cascade(G, prior_probs, edge_dict, num_sim)\n",
    "    end = time.time()\n",
    "    time_mc[i] = end - start\n",
    "    true_posterior_tensor = torch.tensor(\n",
    "        [ic[node] for node in ic],\n",
    "        dtype=torch.float\n",
    "    ).view(-1, 1)\n",
    "\n",
    "    start = time.time()\n",
    "    preds = IC_approx_vectorized(G, edge_dict, prior_probs, T, 1)\n",
    "    end = time.time()\n",
    "    time_ic_apporx[i] = end - start\n",
    "    \n",
    "    preds_IC_approx = torch.tensor(preds, dtype=torch.float32).unsqueeze(1)\n",
    "    rmse[i] = torch.nn.MSELoss()(preds_IC_approx, true_posterior_tensor).item()**0.5\n",
    "\n",
    "    pearson[i] = torch.corrcoef(torch.stack([preds_IC_approx.squeeze(), true_posterior_tensor.squeeze()]))[0, 1]\n",
    "    spearman[i], _ = spearmanr(preds_IC_approx.squeeze(),\n",
    "                              true_posterior_tensor.squeeze())\n",
    "\n",
    "    y_true = true_posterior_tensor.squeeze().numpy()\n",
    "    y_score = preds_IC_approx.squeeze().numpy()\n",
    "    threshold = np.percentile(y_true, percentile)\n",
    "    y_binary = (y_true >= threshold).astype(int)\n",
    "    auc[i] = roc_auc_score(y_binary, y_score)\n",
    "    \n",
    "summarise_stats(rmse, pearson, spearman, auc, time_ic_apporx, time_mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8c716-830d-4d5c-9a05-84ec9cce3b81",
   "metadata": {},
   "source": [
    "## Anybeat & Advogato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c7da881-ebfd-49ab-bbcc-1cf43e7d5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_directed_graph_from_edges(file_path):\n",
    "    \"\"\"\n",
    "    Reads a file containing edge list data and creates a directed graph using NetworkX.\n",
    "\n",
    "    Each line in the file should contain two integers: source target\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the edge list file.\n",
    "\n",
    "    Returns:\n",
    "    - G (networkx.DiGraph): Directed graph constructed from the edge list.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()  # Directed graph\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():  # skip empty lines\n",
    "                source, target = map(int, line.strip().split())\n",
    "                G.add_edge(source, target)\n",
    "\n",
    "    return G\n",
    "\n",
    "def load_weighted_directed_graph(file_path):\n",
    "    \"\"\"\n",
    "    Loads a weighted directed graph from a file.\n",
    "    Ignores lines starting with '%'. Assumes each valid line has: source target weight\n",
    "\n",
    "    Returns:\n",
    "    - G (nx.DiGraph): The directed graph.\n",
    "    - edge_weight (dict): Dictionary with (u, v) -> weight mapping.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    edge_weight = {}\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('%'):\n",
    "                continue  # Skip comments and empty lines\n",
    "\n",
    "            parts = line.split()\n",
    "            if len(parts) != 3:\n",
    "                continue  # Skip malformed lines\n",
    "\n",
    "            u, v = int(parts[0]), int(parts[1])\n",
    "            w = float(parts[2])\n",
    "\n",
    "            G.add_edge(u, v, weight=w)\n",
    "            edge_weight[(u, v)] = w\n",
    "\n",
    "    return G, edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1380942c-2b69-4084-892a-4ad397f9a390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:\n",
      " mean=0.06650379837585291,\n",
      " ci_low=0.05946359044118863,\n",
      " ci_high=0.07354400631051719,\n",
      " std=0.009336497105862238\n",
      "pearson:\n",
      " mean=0.9697460353374481,\n",
      " ci_low=0.966707976616785,\n",
      " ci_high=0.9727840940581112,\n",
      " std=0.004028975666080733\n",
      "spearman:\n",
      " mean=0.9671038871004273,\n",
      " ci_low=0.9590673325514546,\n",
      " ci_high=0.9751404416494,\n",
      " std=0.010657819908719066\n",
      "auc:\n",
      " mean=0.9924521677055849,\n",
      " ci_low=0.9898154165407712,\n",
      " ci_high=0.9950889188703985,\n",
      " std=0.0034967745054727663\n",
      "time_ic_apporx:\n",
      " mean=0.06618521213531495,\n",
      " ci_low=0.05633780439727954,\n",
      " ci_high=0.07603261987335036,\n",
      " std=0.013059315108254302\n",
      "time_mc:\n",
      " mean=150.1168033361435,\n",
      " ci_low=131.10356861711094,\n",
      " ci_high=169.13003805517607,\n",
      " std=25.214739759784127\n"
     ]
    }
   ],
   "source": [
    "prob_selected = 0.1\n",
    "method=\"degree_based\"\n",
    "num_sim=10000\n",
    "low=0\n",
    "high=1/3\n",
    "percentile=95\n",
    "T=20\n",
    "num_iter = 10\n",
    "\n",
    "rmse_anybeat = np.zeros(num_iter)\n",
    "pearson_anybeat = np.zeros(num_iter)\n",
    "spearman_anybeat = np.zeros(num_iter)\n",
    "auc_anybeat = np.zeros(num_iter)\n",
    "time_ic_apporx_anybeat = np.zeros(num_iter)\n",
    "time_mc_anybeat = np.zeros(num_iter)\n",
    "\n",
    "G_anybeat = load_directed_graph_from_edges(\"soc-anybeat/soc-anybeat.edges\")\n",
    "edge_dict_anybeat = generate_edge_probabilities(G_anybeat,method=method,low=low, high=high)\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    mask = torch.rand(len(G_anybeat.nodes())) < prob_selected\n",
    "    prior_probs_anybeat = mask.float()  * torch.rand(len(G_anybeat.nodes()))\n",
    "    \n",
    "    start = time.time()\n",
    "    ic_anybeat = optimized_independent_cascade(G_anybeat, prior_probs_anybeat, edge_dict_anybeat, num_sim)\n",
    "    end = time.time()\n",
    "    time_mc_anybeat[i] = end - start\n",
    "    true_posterior_tensor_anybeat = torch.tensor(\n",
    "        [ic_anybeat[node] for node in ic_anybeat],\n",
    "        dtype=torch.float\n",
    "    ).view(-1, 1)\n",
    "    \n",
    "    start = time.time()\n",
    "    preds_anybeat = IC_approx_vectorized(G_anybeat, edge_dict_anybeat, prior_probs_anybeat, T, 1)\n",
    "    end = time.time()\n",
    "    time_ic_apporx_anybeat[i] = end - start\n",
    "    \n",
    "    preds_IC_approx_anybeat = torch.tensor(preds_anybeat, dtype=torch.float32).unsqueeze(1)\n",
    "    rmse_anybeat[i] = torch.nn.MSELoss()(preds_IC_approx_anybeat, true_posterior_tensor_anybeat).item()**0.5\n",
    "    \n",
    "    pearson_anybeat[i] = torch.corrcoef(torch.stack([preds_IC_approx_anybeat.squeeze(), true_posterior_tensor_anybeat.squeeze()]))[0, 1]\n",
    "    spearman_anybeat[i], _ = spearmanr(preds_IC_approx_anybeat.squeeze(),\n",
    "                              true_posterior_tensor_anybeat.squeeze())\n",
    "    \n",
    "    y_true = true_posterior_tensor_anybeat.squeeze().numpy()\n",
    "    y_score = preds_IC_approx_anybeat.squeeze().numpy()\n",
    "    threshold = np.percentile(y_true, percentile)\n",
    "    y_binary = (y_true >= threshold).astype(int)\n",
    "    auc_anybeat[i] = roc_auc_score(y_binary, y_score)\n",
    "\n",
    "summarise_stats(rmse_anybeat, pearson_anybeat, spearman_anybeat, auc_anybeat, time_ic_apporx_anybeat, time_mc_anybeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c0e7249-2fe0-4677-a4c7-77ed53d41f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:\n",
      " mean=0.037563673690395885,\n",
      " ci_low=0.03577886026847289,\n",
      " ci_high=0.03934848711231888,\n",
      " std=0.0023669620986958412\n",
      "pearson:\n",
      " mean=0.9863605558872223,\n",
      " ci_low=0.9859092629794423,\n",
      " ci_high=0.9868118487950023,\n",
      " std=0.0005984901250767988\n",
      "spearman:\n",
      " mean=0.9967038268130173,\n",
      " ci_low=0.9965585768402414,\n",
      " ci_high=0.9968490767857932,\n",
      " std=0.00019262583762209617\n",
      "auc:\n",
      " mean=0.997084649588662,\n",
      " ci_low=0.9961340172387791,\n",
      " ci_high=0.998035281938545,\n",
      " std=0.0012606980171309234\n",
      "time_ic_apporx:\n",
      " mean=0.047872185707092285,\n",
      " ci_low=0.038153697425194755,\n",
      " ci_high=0.057590673988989816,\n",
      " std=0.012888346276042099\n",
      "time_mc:\n",
      " mean=50.73339323997497,\n",
      " ci_low=45.170897128664244,\n",
      " ci_high=56.2958893512857,\n",
      " std=7.376803260158133\n"
     ]
    }
   ],
   "source": [
    "prob_selected = 0.1\n",
    "method=\"degree_based\"\n",
    "num_sim=10000\n",
    "low=0\n",
    "high=1/3\n",
    "percentile=95\n",
    "T=5\n",
    "num_iter = 10\n",
    "\n",
    "rmse_advogato = np.zeros(num_iter)\n",
    "pearson_advogato = np.zeros(num_iter)\n",
    "spearman_advogato = np.zeros(num_iter)\n",
    "auc_advogato = np.zeros(num_iter)\n",
    "time_ic_apporx_advogato = np.zeros(num_iter)\n",
    "time_mc_advogato = np.zeros(num_iter)\n",
    "\n",
    "G_advogato, weights_advogato = load_weighted_directed_graph(\"soc-advogato/soc-advogato.edges\")\n",
    "edge_dict_advogato = generate_edge_probabilities(G_advogato,method=method,low=low, high=high)\n",
    "\n",
    "for edge in edge_dict_advogato:\n",
    "    edge_dict_advogato[edge] *= weights_advogato[edge]\n",
    "    \n",
    "for i in range(num_iter):\n",
    "    mask = torch.rand(len(G_advogato.nodes())) < prob_selected\n",
    "    prior_probs_advogato = mask.float()  * torch.rand(len(G_advogato.nodes()))\n",
    "    \n",
    "    start = time.time()\n",
    "    ic_advogato = optimized_independent_cascade(G_advogato, prior_probs_advogato, edge_dict_advogato, num_sim)\n",
    "    end = time.time()\n",
    "    time_mc_advogato[i] = end - start\n",
    "    true_posterior_tensor_advogato = torch.tensor(\n",
    "        [ic_advogato[node] for node in ic_advogato],\n",
    "        dtype=torch.float\n",
    "    ).view(-1, 1)\n",
    "    \n",
    "    start = time.time()\n",
    "    preds_advogato = IC_approx_vectorized(G_advogato, edge_dict_advogato, prior_probs_advogato, T, 1)\n",
    "    end = time.time()\n",
    "    time_ic_apporx_advogato[i] = end - start\n",
    "    \n",
    "    preds_IC_approx_advogato = torch.tensor(preds_advogato, dtype=torch.float32).unsqueeze(1)\n",
    "    rmse_advogato[i] = torch.nn.MSELoss()(preds_IC_approx_advogato, true_posterior_tensor_advogato).item()**0.5\n",
    "    \n",
    "    pearson_advogato[i] = torch.corrcoef(torch.stack([preds_IC_approx_advogato.squeeze(), true_posterior_tensor_advogato.squeeze()]))[0, 1]\n",
    "    spearman_advogato[i], _ = spearmanr(preds_IC_approx_advogato.squeeze(),\n",
    "                              true_posterior_tensor_advogato.squeeze())\n",
    "    \n",
    "    y_true = true_posterior_tensor_advogato.squeeze().numpy()\n",
    "    y_score = preds_IC_approx_advogato.squeeze().numpy()\n",
    "    threshold = np.percentile(y_true, percentile)\n",
    "    y_binary = (y_true >= threshold).astype(int)\n",
    "    auc_advogato[i] = roc_auc_score(y_binary, y_score)\n",
    "\n",
    "summarise_stats(rmse_advogato, pearson_advogato, spearman_advogato, auc_advogato, time_ic_apporx_advogato, time_mc_advogato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba806708-cf0c-48d5-ae2e-75d705e02231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:\n",
      " mean=0.008081818563251842,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "pearson:\n",
      " mean=0.9989129304885864,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "spearman:\n",
      " mean=0.9706517710905714,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "auc:\n",
      " mean=0.9999418947368421,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "time_ic_apporx:\n",
      " mean=0.058057546615600586,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n",
      "time_mc:\n",
      " mean=5.283751964569092,\n",
      " ci_low=nan,\n",
      " ci_high=nan,\n",
      " std=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matic/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/matic/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "num_nodes=10000\n",
    "num_edges_per_node=5 #2,5,10\n",
    "prob_selected = 0.1\n",
    "edge_method=\"weighted_sum\"\n",
    "num_graphs=1\n",
    "num_sim=1000\n",
    "low=0\n",
    "high=1/3\n",
    "percentile=95\n",
    "T=15 # 5, 10, 15\n",
    "num_node_features=5\n",
    "num_edge_features=5\n",
    "attribute_distribution=\"normal\"\n",
    "max_edge=1\n",
    "normal = False\n",
    "if normal:\n",
    "    node_weights=np.random.normal(size=num_node_features)\n",
    "    node_weights_source=np.random.normal(size=num_node_features)\n",
    "    node_weights_sink=np.random.normal(size=num_node_features)\n",
    "    epsilon=np.random.normal(size=1)*-4\n",
    "    edge_weights=np.random.normal(size=num_edge_features)\n",
    "else:\n",
    "    node_weights=np.random.rand(num_node_features)*2-1\n",
    "    node_weights_source=np.random.rand(num_node_features)*2-1\n",
    "    node_weights_sink=np.random.rand(num_node_features)*2-1\n",
    "    epsilon=np.random.rand(1)*-4\n",
    "    edge_weights=np.random.rand(num_edge_features)*2-1\n",
    "\n",
    "rmse = np.zeros(num_graphs)\n",
    "pearson = np.zeros(num_graphs)\n",
    "spearman = np.zeros(num_graphs)\n",
    "auc = np.zeros(num_graphs)\n",
    "time_ic_apporx = np.zeros(num_graphs)\n",
    "time_mc = np.zeros(num_graphs)\n",
    "\n",
    "for i in range(num_graphs):\n",
    "    G, prior_probs, edge_dict = generate_barabasi_albert_attribute_graph(num_nodes,\n",
    "                                                                    num_edges_per_node,\n",
    "                                                                    num_node_features=num_node_features,\n",
    "                                                                    num_edge_features=num_edge_features,\n",
    "                                                                    node_weights=node_weights,\n",
    "                                                                    edge_weights=edge_weights,\n",
    "                                                                    edge_method=edge_method,\n",
    "                                                                    max_edge=max_edge,\n",
    "                                                                    prob_selected=prob_selected,\n",
    "                                                                    attribute_distribution=attribute_distribution)\n",
    "\n",
    "    edge_dict_deg = generate_edge_probabilities(G,method=\"degree_based\",low=low, high=high)\n",
    "\n",
    "    for edge in edge_dict:\n",
    "        edge_dict[edge] *= edge_dict_deg[edge]\n",
    "    \n",
    "    start = time.time()\n",
    "    ic = optimized_independent_cascade(G, prior_probs, edge_dict, num_sim)\n",
    "    end = time.time()\n",
    "    time_mc[i] = end - start\n",
    "    true_posterior_tensor = torch.tensor(\n",
    "        [ic[node] for node in ic],\n",
    "        dtype=torch.float\n",
    "    ).view(-1, 1)\n",
    "\n",
    "    start = time.time()\n",
    "    preds = IC_approx_vectorized(G, edge_dict, prior_probs, T, 1)\n",
    "    end = time.time()\n",
    "    time_ic_apporx[i] = end - start\n",
    "    \n",
    "    preds_IC_approx = torch.tensor(preds, dtype=torch.float32).unsqueeze(1)\n",
    "    rmse[i] = torch.nn.MSELoss()(preds_IC_approx, true_posterior_tensor).item()**0.5\n",
    "\n",
    "    pearson[i] = torch.corrcoef(torch.stack([preds_IC_approx.squeeze(), true_posterior_tensor.squeeze()]))[0, 1]\n",
    "    spearman[i], _ = spearmanr(preds_IC_approx.squeeze(),\n",
    "                              true_posterior_tensor.squeeze())\n",
    "\n",
    "    y_true = true_posterior_tensor.squeeze().numpy()\n",
    "    y_score = preds_IC_approx.squeeze().numpy()\n",
    "    threshold = np.percentile(y_true, percentile)\n",
    "    y_binary = (y_true >= threshold).astype(int)\n",
    "    auc[i] = roc_auc_score(y_binary, y_score)\n",
    "\n",
    "summarise_stats(rmse, pearson, spearman, auc, time_ic_apporx, time_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18eab59-2228-437d-b6ea-2054dbd702c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
